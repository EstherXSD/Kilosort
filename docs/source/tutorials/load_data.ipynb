{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data from different formats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kilosort 4 natively supports data in binary format, `.bin`. The simplest\n",
    "way to save your data in this format is to load it into memory one chunk at a\n",
    "time and save it to a `.bin` file using `NumPy's memmap` function. However,\n",
    "if you aren't comfortable with that process, the `SpikeInterface` package\n",
    "can load most common electrophysiology formats in a standardized way that makes\n",
    "it easy to extract the data.\n",
    "\n",
    "To follow the steps in this notebook, you will first need to install\n",
    "`SpikeInterface`:\n",
    "```\n",
    "    pip install spikeinterface[full]\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each data format, `SpikeInterface` has a `read_<format>` utility that loads\n",
    "the data as a `RecordingExtractor` object, which we can  use to extract the data\n",
    "and relevant meta information like sampling frequency. The following example\n",
    "shows the steps for the `Open Ephys` data format. At the bottom of the notebook,\n",
    "there are notes on how to load several other common formats. For all cells after\n",
    "the first, all steps should be the same regardless of format."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from spikeinterface.extractors import read_openephys\n",
    "\n",
    "# Specify the path where the data will be copied to, and where Kilosort 4\n",
    "# results will be saved.\n",
    "DATA_DIRECTORY = Path('/home/example_path')  # NOTE: You should change this\n",
    "DATA_PATH = DATA_DIRECTORY / 'data.bin'\n",
    "# Create filepath if it doesn't exist\n",
    "DATA_DIRECTORY.mkdir(parents=True, exist_ok=True)\n",
    "# Specify path to your existing data\n",
    "filepath = Path(\".../Record_Node_101\")       # NOTE: You must change this\n",
    "# Load existing data with spikeinterface\n",
    "# NOTE: Open Ephys data can have multiple streams, specify `stream_id` to\n",
    "#       load different ones.\n",
    "recording = read_openephys(filepath, stream_id='0')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Get information about channel count, sampling frequency, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = recording.get_num_channels()\n",
    "s = recording.get_num_segments()\n",
    "fs = recording.get_sampling_frequency()\n",
    "N = recording.get_total_samples()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create a new binary file and copy the data to it 60,000 samples at a time. Depending on your system's memory, you could increase or decrease the number of samples loaded on each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.memmap(DATA_PATH, dtype='int16', mode='w+', shape=(N,c))\n",
    "NT = 60000  # Number of samples to copy at a time\n",
    "\n",
    "# Copy data to binary file, 60000 samples at a time\n",
    "# (same as Kilosort's default batch size).\n",
    "for k in range(s):\n",
    "    n = recording.get_num_samples(segment_index=k)\n",
    "    i = 0 + k*NT\n",
    "    while i < n:\n",
    "        j = i + NT if (i + NT) < n else n\n",
    "        t = recording.get_traces(segment_index=k, start_frame=i, end_frame=j)\n",
    "        y[i:j,:] = t\n",
    "        y.flush()\n",
    "        i += NT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Verify that the data was copied correctly, once again one chunk at a time. If the data is not matched to within 8 decimal places, this cell will raise an `AssertionError`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y = np.memmap(DATA_PATH, dtype='int16', mode='r', shape=(N,c))\n",
    "for k in range(s):\n",
    "    n = recording.get_num_samples(segment_index=k)\n",
    "    i = 0 + k*NT\n",
    "    while i < n:\n",
    "        j = i + NT if (i + NT) < n else n\n",
    "        t = recording.get_traces(segment_index=k, start_frame=i, end_frame=j)\n",
    "        assert np.allclose(t, new_y[i:j,:])\n",
    "        i += NT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, it's a good idea to open the Kilosort gui and check that the\n",
    "data and probe appear to have been loaded correctly and no settings need to be\n",
    "tweaked. You will need to input the path to the binary datafile, the folder where\n",
    "results should be saved, and select a probe file.\n",
    "\n",
    "```python -m kilosort```\n",
    "\n",
    "From there, you can either launch Kilosort using the GUI or run the\n",
    "next notebook cell to run it through the API."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Run Kilosort (API)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in this case, we don't actually need to specify a probe since it's\n",
    "the same as the default Neuropixels 1 configuration. For handling different\n",
    "probe layouts, provide your own .prb file and/or see the tutorial on creating a\n",
    "new probe file from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kilosort import run_kilosort, default_settings, PROBE_DIR, io\n",
    "from kilosort.utils import download_probes\n",
    "\n",
    "# TODO: explain difference between the two channel count settings.\n",
    "settings = default_settings()\n",
    "settings['fs'] = fs                      # Sampling rate\n",
    "settings['NchanTOT'] = c                 # Number of channels\n",
    "settings['n_chan_bin'] = c               # Number of channels\n",
    "settings['data_dir'] = DATA_DIRECTORY    # Directory containing binary file.\n",
    "\n",
    "# NOTE: The only necessary step here is `probe = io.load_probe(probe_path)`.\n",
    "#       The rest is specific to Kilosort's default probe files.\n",
    "download_probes()\n",
    "probe_name = 'neuropixPhase3B1_kilosortChanMap.mat'\n",
    "probe_path = PROBE_DIR / probe_name\n",
    "probe = io.load_probe(probe_path)\n",
    "\n",
    "# This command will both run the spike-sorting analysis and save the results to\n",
    "# `DATA_DIRECTORY`.\n",
    "ops, st, clu, tF, Wall, similar_templates, is_ref, est_contam_rate = run_kilosort(\n",
    "    settings=settings, probe=probe, filename=DATA_PATH\n",
    "    )\n",
    "\n",
    "# TODO: explain the variables that are returned"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whether you used the gui or the API, the results can now be browsed in Phy from a terminal with:\n",
    "\n",
    "```phy template-gui <DATA_DIRECTORY>/kilosort4/params.py```\n",
    "\n",
    "(replacing DATA_DIRECTORY with the appropriate path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions for additional data formats\n",
    "\n",
    "The following cells demonstrate how to load other dataformats using spikeinterface.\n",
    "Use these code snippets to modify the first cell of this notebook to work with\n",
    "different datasets.\n",
    "\n",
    "See [SpikeInterface's documentation](https://spikeinterface.readthedocs.io/en/latest/modules/extractors.html) for additional details."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MEArec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spikeinterface.extractors import read_mearec\n",
    "# NOTE: need to `pip install MEArec`\n",
    "# Provide path to HDF5 file.\n",
    "filepath = Path(\".../mearec_test_10s.h5\")\n",
    "recording, sorting_true = read_mearec(filepath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SpikeGLX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: You do not need to load SpikeGLX data this way. It is already saved in\n",
    "#       binary format, so you should just point Kilosort 4 to the .bin file.\n",
    "from spikeinterface.extractors import read_spikeglx\n",
    "# Provide path to directory containing .bin file.\n",
    "filepath = Path(\".../TEST_20210920_0_g0/\")\n",
    "recording = read_spikeglx(filepath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blackrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spikeinterface.extractors import read_blackrock\n",
    "# Provide path to nsX file, not nev file.\n",
    "filepath = Path(\".../file_spec_3_0.ns6\")\n",
    "recording = read_blackrock(filepath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neuralynx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spikeinterface.extractors import read_neuralynx\n",
    "# Provide path to directory containing .Ncs file(s).\n",
    "filepath = Path(\"C:/code/ephy_testing_data/neuralynx/BML/original_data/\")\n",
    "recording = read_neuralynx(filepath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NWB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spikeinterface.extractors import read_nwb_recording\n",
    "# NOTE: SpikeInterface appears to be picky about which NWB formats it will load.\n",
    "#       If you encounter issues, please reach out for assistance.\n",
    "filepath = Path(\".../ecephys_tutorial_v2.5.0.nwb\")\n",
    "recording = read_nwb_recording(filepath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spikeinterface.extractors import read_intan\n",
    "# NOTE: You will need to select the appropriate data stream. If you run without\n",
    "#       specifying `stream_id`, you will get an error message explaining what\n",
    "#       each stream corresponds to.\n",
    "filepath = Path(\".../intan_rhs_test_1.rhs\")\n",
    "recording = read_intan(filepath, stream_id='0')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kilosort",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
