{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading other data formats with SpikeInterface"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kilosort 4 natively supports data in binary format, `.bin`. The simplest\n",
    "way to save your data in this format is to load it into memory one chunk at a\n",
    "time and save it to a `.bin` file using `NumPy's memmap` function. However,\n",
    "if you aren't comfortable with that process, the `SpikeInterface` package\n",
    "can load most common electrophysiology formats in a standardized way that makes\n",
    "it easy to extract the data.\n",
    "\n",
    "To follow the steps in this notebook, you will first need to install\n",
    "`SpikeInterface`:\n",
    "```\n",
    "    pip install spikeinterface[full]\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each data format, `SpikeInterface` has a `read_<format>` utility that loads\n",
    "the data as a `RecordingExtractor` object, which we can  use to extract the data\n",
    "and relevant meta information like sampling frequency. The following example\n",
    "shows the steps for the `Open Ephys` data format. At the bottom of the notebook,\n",
    "there are notes on how to load several other common formats. For all cells after\n",
    "the first, all steps should be the same regardless of format."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from spikeinterface.extractors import read_openephys\n",
    "\n",
    "# Specify the path where the data will be copied to, and where Kilosort 4\n",
    "# results will be saved.\n",
    "DATA_DIRECTORY = Path('/home/example_path')  # NOTE: You should change this\n",
    "DATA_PATH = DATA_DIRECTORY / 'data.bin'\n",
    "# Create filepath if it doesn't exist\n",
    "DATA_DIRECTORY.mkdir(parents=True, exist_ok=True)\n",
    "# Specify path to your existing data\n",
    "filepath = Path(\".../Record_Node_101\")       # NOTE: You must change this\n",
    "# Load existing data with spikeinterface\n",
    "# NOTE: Open Ephys data can have multiple streams, specify `stream_id` to\n",
    "#       load different ones.\n",
    "recording = read_openephys(filepath, stream_id='0')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Get information about channel count, sampling frequency, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Don't use `recording.get_num_channels()` for number of channels, it\n",
    "#       sometimes includes channels that are not part of the data.\n",
    "c = recording.get_traces(segment_index=0, start_frame=0, end_frame=1).shape[1]\n",
    "s = recording.get_num_segments()\n",
    "fs = recording.get_sampling_frequency()\n",
    "N = recording.get_total_samples()\n",
    "dtype = recording.get_dtype()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create a new binary file and copy the data to it 60,000 samples at a time. Depending on your system's memory, you could increase or decrease the number of samples loaded on each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.memmap(DATA_PATH, dtype=dtype, mode='w+', shape=(N,c))\n",
    "NT = 60000  # Number of samples to copy at a time\n",
    "total_chunks = int(np.ceil(N/NT))\n",
    "\n",
    "# Copy data to binary file, 60000 samples at a time\n",
    "# (same as Kilosort's default batch size).\n",
    "chunk = 0\n",
    "for k in range(s):\n",
    "    n = recording.get_num_samples(segment_index=k)\n",
    "    i = 0 + k*NT\n",
    "    while i < n:\n",
    "        if chunk % 50 == 0:\n",
    "            print(f'Copying chunk {chunk}/{total_chunks} ...')\n",
    "        j = i + NT if (i + NT) < n else n\n",
    "        t = recording.get_traces(segment_index=k, start_frame=i, end_frame=j)\n",
    "        y[i:j,:] = t\n",
    "        y.flush()\n",
    "        i += NT\n",
    "        chunk += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. (Optional) Verify that the data was copied correctly, once again one chunk at a time. If the data is not matched to within 8 decimal places, this cell will raise an `AssertionError`. Note that this process can take almost as long as copying the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y = np.memmap(DATA_PATH, dtype=dtype, mode='r', shape=(N,c))\n",
    "chunk = 0\n",
    "chunk_limit = np.inf  # np.inf to check all data\n",
    "\n",
    "for k in range(s):\n",
    "    n = recording.get_num_samples(segment_index=k)\n",
    "    i = 0 + k*NT\n",
    "    while i < n:\n",
    "        if chunk > chunk_limit:\n",
    "            break\n",
    "        if chunk % 50 == 0:\n",
    "            print(f'Verifying chunk {chunk}/{total_chunks} ...')\n",
    "\n",
    "        j = i + NT if (i + NT) < n else n\n",
    "        t = recording.get_traces(segment_index=k, start_frame=i, end_frame=j)\n",
    "        assert np.all(t == new_y[i:j,:])\n",
    "        i += NT\n",
    "        chunk += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, it's a good idea to open the Kilosort gui and check that the\n",
    "data and probe appear to have been loaded correctly and no settings need to be\n",
    "tweaked. You will need to input the path to the binary datafile, the folder where\n",
    "results should be saved, and select a probe file.\n",
    "\n",
    "```python -m kilosort```\n",
    "\n",
    "From there, you can either launch Kilosort using the GUI or run the\n",
    "next notebook cell to run it through the API."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Run Kilosort (API)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in this case, we don't actually need to specify a probe since it's\n",
    "the same as the default Neuropixels 1 configuration. For handling different\n",
    "probe layouts, provide your own .prb file and/or see the tutorial on creating a\n",
    "new probe file from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kilosort import run_kilosort, default_settings, PROBE_DIR, io\n",
    "from kilosort.utils import download_probes\n",
    "\n",
    "# TODO: explain difference between the two channel count settings.\n",
    "settings = default_settings()\n",
    "settings['fs'] = fs                      # Sampling rate\n",
    "settings['NchanTOT'] = c                 # Number of channels\n",
    "settings['n_chan_bin'] = c               # Number of channels\n",
    "settings['data_dir'] = DATA_DIRECTORY    # Directory containing binary file.\n",
    "\n",
    "# NOTE: The only necessary step here is `probe = io.load_probe(probe_path)`.\n",
    "#       The rest is specific to Kilosort's default probe files.\n",
    "download_probes()\n",
    "probe_name = 'neuropixPhase3B1_kilosortChanMap.mat'\n",
    "probe_path = PROBE_DIR / probe_name\n",
    "probe = io.load_probe(probe_path)\n",
    "# NOTE: If the dataset loaded through spikeinterface contains probe information\n",
    "#       (some .nwb files, for example), you can use `recording.get_probe()`\n",
    "#       to get the relevant information and then follow the steps at the end of\n",
    "#       this notebook to save to a .prb file that can be read into Kilosort.\n",
    "\n",
    "# This command will both run the spike-sorting analysis and save the results to\n",
    "# `DATA_DIRECTORY`.\n",
    "ops, st, clu, tF, Wall, similar_templates, is_ref, est_contam_rate = run_kilosort(\n",
    "    settings=settings, probe=probe, filename=DATA_PATH,\n",
    "    # dtype=dtype  # TODO: add this option after dtype pull request is approved\n",
    "    )\n",
    "\n",
    "# TODO: explain the variables that are returned"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whether you used the gui or the API, the results can now be browsed in Phy from a terminal with:\n",
    "\n",
    "```phy template-gui <DATA_DIRECTORY>/kilosort4/params.py```\n",
    "\n",
    "(replacing DATA_DIRECTORY with the appropriate path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions for additional data formats\n",
    "\n",
    "The following cells demonstrate how to load other dataformats using spikeinterface.\n",
    "Use these code snippets to modify the first cell of this notebook to work with\n",
    "different datasets.\n",
    "\n",
    "See [SpikeInterface's documentation](https://spikeinterface.readthedocs.io/en/latest/modules/extractors.html) for additional details."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SpikeGLX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: You do not need to load SpikeGLX data this way. It is already saved in\n",
    "#       binary format, so you should just point Kilosort 4 to the .bin file.\n",
    "from spikeinterface.extractors import read_spikeglx\n",
    "# Provide path to directory containing .bin file.\n",
    "filepath = Path(\".../TEST_20210920_0_g0/\")\n",
    "recording = read_spikeglx(filepath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blackrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spikeinterface.extractors import read_blackrock\n",
    "# Provide path to nsX file, not nev file.\n",
    "filepath = Path(\".../file_spec_3_0.ns6\")\n",
    "recording = read_blackrock(filepath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neuralynx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spikeinterface.extractors import read_neuralynx\n",
    "# Provide path to directory containing .Ncs file(s).\n",
    "filepath = Path(\"C:/code/ephy_testing_data/neuralynx/BML/original_data/\")\n",
    "recording = read_neuralynx(filepath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NWB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spikeinterface.extractors import read_nwb_recording\n",
    "# NOTE: SpikeInterface appears to be picky about which NWB formats it will load.\n",
    "#       If you encounter issues, please reach out for assistance.\n",
    "# NOTE: You may need to specify additional keyword arguments for\n",
    "#       `read_nwb_recording`, such as `electrical_series_name`. Any required\n",
    "#       arguments should be clearly spelled out by an error message.\n",
    "filepath = Path(\".../ecephys_tutorial_v2.5.0.nwb\")\n",
    "recording = read_nwb_recording(filepath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spikeinterface.extractors import read_intan\n",
    "# NOTE: You will need to select the appropriate data stream. If you run without\n",
    "#       specifying `stream_id`, you will get an error message explaining what\n",
    "#       each stream corresponds to.\n",
    "filepath = Path(\".../intan_rhs_test_1.rhs\")\n",
    "recording = read_intan(filepath, stream_id='0')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "## Exporting probes from SpikeInterface\n",
    "\n",
    "To create a new probe file, we can use `ProbeInterface` (a subpackage of `SpikeInterface`).\n",
    "You will also need `matplotlib` if you want to visualize the probe geometry (recommended).\n",
    "\n",
    "You can follow the steps in [this ProbeInterface tutorial](https://probeinterface.readthedocs.io/en/main/examples/ex_01_generate_probe_from_sratch.html)\n",
    "to create a new probe from scratch, or to plot a probe to check that it is\n",
    "configured correctly.\n",
    "\n",
    "Then use the following steps to export to a .prb file that can be read by\n",
    "Kilosort4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from probeinterface import ProbeGroup, write_prb\n",
    "\n",
    "probe = ...  # From SpikeInterface tutorial, or recording.get_probe()\n",
    "\n",
    "# Multiple probes can be added to a ProbeGroup. We only have one, but a\n",
    "# ProbeGroup wrapper is still necessary for `write_prb` to work.\n",
    "pg = ProbeGroup()\n",
    "pg.add_probe(probe)\n",
    "# CHANGE THIS PATH to wherever you want to save your probe file.\n",
    "write_prb('.../test_prb.prb', pg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the probe object must have channel indices specified in order to save\n",
    "to a .prb file. If `write_prb` results in an error indicating these are not set,\n",
    "you can use the `probe.set_device_channel_indices` method to set them. For example,\n",
    "for a 24-channel probe with all contacts connected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must set channel indices for .prb files.\n",
    "# Indicate \"not connected\" with a value of -1.\n",
    "probe.set_device_channel_indices(np.arange(24))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kilosort",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
